[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project 2/karlanlist.html",
    "href": "projects/project 2/karlanlist.html",
    "title": "Nitya's Website and Portfolio",
    "section": "",
    "text": "import pandas as pd\n\nfile_path = 'karlan_list_2007.dta'\ndf1 = pd.read_stata(file_path)\n\nprint(df1.head())\n\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]\nEDA and Descriptive Analysis\ndf1.columns\n\nIndex(['treatment', 'control', 'ratio', 'ratio2', 'ratio3', 'size', 'size25',\n       'size50', 'size100', 'sizeno', 'ask', 'askd1', 'askd2', 'askd3', 'ask1',\n       'ask2', 'ask3', 'amount', 'gave', 'amountchange', 'hpa', 'ltmedmra',\n       'freq', 'years', 'year5', 'mrm2', 'dormant', 'female', 'couple',\n       'state50one', 'nonlit', 'cases', 'statecnt', 'stateresponse',\n       'stateresponset', 'stateresponsec', 'stateresponsetminc', 'perbush',\n       'close25', 'red0', 'blue0', 'redcty', 'bluecty', 'pwhite', 'pblack',\n       'page18_39', 'ave_hh_sz', 'median_hhincome', 'powner', 'psch_atlstba',\n       'pop_propurban'],\n      dtype='object')\ndf1.dtypes\n\ntreatment                 int8\ncontrol                   int8\nratio                 category\nratio2                    int8\nratio3                    int8\nsize                  category\nsize25                    int8\nsize50                    int8\nsize100                   int8\nsizeno                    int8\nask                   category\naskd1                     int8\naskd2                     int8\naskd3                     int8\nask1                     int16\nask2                     int16\nask3                     int16\namount                 float32\ngave                      int8\namountchange           float32\nhpa                    float32\nltmedmra                  int8\nfreq                     int16\nyears                  float64\nyear5                     int8\nmrm2                   float64\ndormant                   int8\nfemale                 float64\ncouple                 float64\nstate50one                int8\nnonlit                 float64\ncases                  float64\nstatecnt               float32\nstateresponse          float32\nstateresponset         float32\nstateresponsec         float32\nstateresponsetminc     float32\nperbush                float32\nclose25                float64\nred0                   float64\nblue0                  float64\nredcty                 float64\nbluecty                float64\npwhite                 float32\npblack                 float32\npage18_39              float32\nave_hh_sz              float32\nmedian_hhincome        float64\npowner                 float32\npsch_atlstba           float32\npop_propurban          float32\ndtype: object\ncolumn_means = df1.mean(numeric_only=True)\nprint(\"Means of each column:\")\nprint(column_means)\n\nMeans of each column:\ntreatment                 0.666813\ncontrol                   0.333187\nratio2                    0.222311\nratio3                    0.222211\nsize25                    0.166723\nsize50                    0.166623\nsize100                   0.166723\nsizeno                    0.166743\naskd1                     0.222311\naskd2                     0.222291\naskd3                     0.222211\nask1                     71.501807\nask2                     91.792724\nask3                    111.046263\namount                    0.915694\ngave                      0.020646\namountchange            -52.672016\nhpa                      59.384975\nltmedmra                  0.493720\nfreq                      8.039355\nyears                     6.097540\nyear5                     0.508815\nmrm2                     13.007268\ndormant                   0.523471\nfemale                    0.277669\ncouple                    0.091897\nstate50one                0.000998\nnonlit                    2.473918\ncases                     1.499768\nstatecnt                  5.998820\nstateresponse             0.020627\nstateresponset            0.021989\nstateresponsec            0.017717\nstateresponsetminc        0.004273\nperbush                   0.487940\nclose25                   0.185702\nred0                      0.404452\nblue0                     0.595548\nredcty                    0.510245\nbluecty                   0.488715\npwhite                    0.819599\npblack                    0.086710\npage18_39                 0.321694\nave_hh_sz                 2.429012\nmedian_hhincome       54815.700533\npowner                    0.669418\npsch_atlstba              0.391661\npop_propurban             0.871968\ndtype: float64\n# Check for missing values\nmissing_values = df1.isnull().sum()\nprint(\"Missing values in each column:\")\nprint(missing_values)\n\nMissing values in each column:\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\ndf1['gender'] = df1['female'].apply(lambda x: 'F' if x == 1 else 'M')\ndf = df1.copy()\n\ncategorical_vars = [\n    'ratio', 'ratio2', 'ratio3',\n    'size', 'size25', 'size50', 'size100', 'sizeno',\n    'askd1', 'askd2', 'askd3',\n    'ltmedmra', 'year5', 'dormant',\n    'female', 'couple', 'state50one', \n    'close25', 'red0', 'blue0', 'redcty', 'bluecty'\n]\n\n# Convert to categorical\ndf[categorical_vars] = df[categorical_vars].astype('category')\n\ndf.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nask1\nask2\nask3\namount\ngave\namountchange\nhpa\nfreq\n...\nstateresponsetminc\nperbush\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n50080.000000\n50048.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n71.501807\n91.792724\n111.046263\n0.915694\n0.020646\n-52.672016\n59.384975\n8.039355\n...\n0.004273\n0.487940\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n101.728936\n127.252628\n151.673562\n8.707393\n0.142197\n1267.097656\n71.179871\n11.394454\n...\n0.009112\n0.078733\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n25.000000\n35.000000\n50.000000\n0.000000\n0.000000\n-200412.125000\n0.000000\n0.000000\n...\n-0.047619\n0.090909\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n35.000000\n45.000000\n55.000000\n0.000000\n0.000000\n-50.000000\n30.000000\n2.000000\n...\n-0.001388\n0.444444\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n45.000000\n60.000000\n70.000000\n0.000000\n0.000000\n-30.000000\n45.000000\n4.000000\n...\n0.001779\n0.484848\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n65.000000\n85.000000\n100.000000\n0.000000\n0.000000\n-25.000000\n60.000000\n10.000000\n...\n0.010545\n0.525253\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1500.000000\n1875.000000\n2250.000000\n400.000000\n1.000000\n275.000000\n1000.000000\n218.000000\n...\n0.111111\n0.731959\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 28 columns\ndatadesc = df.describe()\n%pip install tabulate\n\nprint(datadesc.to_markdown(index=False))\n\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.12/site-packages (0.9.0)\nNote: you may need to restart the kernel to use updated packages.\n|    treatment |      control |       ask1 |       ask2 |      ask3 |       amount |          gave |   amountchange |        hpa |        freq |       years |       mrm2 |      nonlit |       cases |       statecnt |   stateresponse |   stateresponset |   stateresponsec |   stateresponsetminc |       perbush |         pwhite |        pblack |    page18_39 |    ave_hh_sz |   median_hhincome |       powner |   psch_atlstba |   pop_propurban |\n|-------------:|-------------:|-----------:|-----------:|----------:|-------------:|--------------:|---------------:|-----------:|------------:|------------:|-----------:|------------:|------------:|---------------:|----------------:|-----------------:|-----------------:|---------------------:|--------------:|---------------:|--------------:|-------------:|-------------:|------------------:|-------------:|---------------:|----------------:|\n| 50083        | 50083        | 50083      | 50083      | 50083     | 50083        | 50083         |      50083     | 50083      | 50083       | 50082       | 50082      | 49631       | 49631       | 50083          |   50083         |   50083          |   50080          |       50080          | 50048         | 48217          | 48047         | 48217        | 48221        |           48209   | 48214        |   48215        |    48217        |\n|     0.666813 |     0.333187 |    71.5018 |    91.7927 |   111.046 |     0.915694 |     0.0206457 |        -52.672 |    59.385  |     8.03935 |     6.09754 |    13.0073 |     2.47392 |     1.49977 |     5.99882    |       0.0206269 |       0.0219885  |       0.0177167  |           0.00427312 |     0.48794   |     0.819599   |     0.0867098 |     0.321694 |     2.42901  |           54815.7 |     0.669418 |       0.391661 |        0.871968 |\n|     0.471357 |     0.471357 |   101.729  |   127.253  |   151.674 |     8.70739  |     0.142197  |       1267.1   |    71.1799 |    11.3945  |     5.50349 |    12.0814 |     1.96153 |     1.15514 |     5.74599    |       0.0051708 |       0.00625721 |       0.00751621 |           0.00911209 |     0.0787327 |     0.16856    |     0.135868  |     0.103039 |     0.378105 |           22027.3 |     0.193405 |       0.186599 |        0.258633 |\n|     0        |     0        |    25      |    35      |    50     |     0        |     0         |    -200412     |     0      |     0       |     0       |     0      |     0       |     0       |     0.00199481 |       0         |       0          |       0          |          -0.047619   |     0.0909091 |     0.00941798 |     0         |     0        |     0        |            5000   |     0        |       0        |        0        |\n|     0        |     0        |    35      |    45      |    55     |     0        |     0         |        -50     |    30      |     2       |     2       |     4      |     1       |     1       |     1.83323    |       0.0181635 |       0.0184932  |       0.0128617  |          -0.00138826 |     0.444444  |     0.755845   |     0.0147292 |     0.258311 |     2.21     |           39181   |     0.560222 |       0.235647 |        0.884929 |\n|     1        |     0        |    45      |    60      |    70     |     0        |     0         |        -30     |    45      |     4       |     5       |     8      |     3       |     1       |     3.5388     |       0.0197095 |       0.0216972  |       0.0198814  |           0.00177869 |     0.484848  |     0.872797   |     0.0365541 |     0.305534 |     2.44     |           50673   |     0.712296 |       0.373744 |        1        |\n|     1        |     1        |    65      |    85      |   100     |     0        |     0         |        -25     |    60      |    10       |     9       |    19      |     4       |     2       |     9.60702    |       0.0230482 |       0.0247027  |       0.0208062  |           0.0105448  |     0.525253  |     0.938827   |     0.090882  |     0.369132 |     2.66     |           66005   |     0.816798 |       0.530036 |        1        |\n|     1        |     1        |  1500      |  1875      |  2250     |   400        |     1         |        275     |  1000      |   218       |    95       |   168      |     6       |     4       |    17.3688     |       0.0769231 |       0.111111   |       0.0526316  |           0.111111   |     0.731959  |     1          |     0.989622  |     0.997544 |     5.27     |          200001   |     1        |       1        |        1        |\n# Generate markdown table to insert into Quarto document\nmarkdown_table = datadesc.to_markdown(index=False)\n\nwith open(\"index.qmd\", \"r\") as f:\n    qmd_text = f.read()\n\nqmd_text = qmd_text.replace(\"&lt;!-- INSERT_DESC_HERE --&gt;\", markdown_table)\n\nwith open(\"index.qmd\", \"w\") as f:\n    f.write(qmd_text)\n# Replace 'give' with the correct column name, e.g., 'gave', which exists in the dfframe\ndfg = df[df['gave'] == 1]\npercentage_gave = (df['gave'].astype(int).sum() / len(df)) * 100\nprint(f\"Percentage of rows where gave = 1: {percentage_gave:.2f}%\")\n\nPercentage of rows where gave = 1: 2.06%\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Key variables and experimental treatment variables to explore\nvariables_to_plot = ['hpa', 'freq', 'years', 'mrm2', 'median_hhincome', \n                     'ratio', 'size', 'ask', 'askd1', 'askd2', 'askd3', ]\n\nimport math\n\n\n\n# Set up the figure layout\nnum_vars = len(variables_to_plot)\nnum_cols = 3\nnum_rows = math.ceil(num_vars / num_cols)\n\nplt.figure(figsize=(18, 5 * num_rows))\n\nfor idx, var in enumerate(variables_to_plot, 1):\n    plt.subplot(num_rows, num_cols, idx)\n    if df[var].dtype in ['int64', 'float64', 'float32', 'int16', 'int8']:\n        sns.histplot(data=df, x=var, hue='gave', multiple='dodge', bins=30)\n        plt.title(f'Histogram of {var} by Gave')\n    else:\n        sns.countplot(data=df, x=var, hue='gave')\n        plt.title(f'Count of {var} by Gave')\n    plt.xlabel(var)\n    plt.ylabel('Count')\n    plt.tight_layout()\n\nplt.show()\n# Key variables and experimental treatment variables to explore\nvariables_to_plot = ['hpa', 'freq', 'years', 'mrm2', 'median_hhincome', \n                     'ratio', 'size', 'ask']\n\n# Set up the figure layout\nnum_vars = len(variables_to_plot)\nnum_cols = 3\nnum_rows = -(-num_vars // num_cols)  # Ceiling division\n\nplt.figure(figsize=(18, 5 * num_rows))\n\n# Plot distribution of donation amount against each variable\nfor idx, var in enumerate(variables_to_plot, 1):\n    plt.subplot(num_rows, num_cols, idx)\n    if var in ['freq', 'hpa']:\n        sns.histplot(data=dfg, x=var, bins=10, kde=True)\n        plt.title(f'Binned Histogram of {var}')\n    elif dfg[var].dtype in ['int64', 'float64']:\n        sns.histplot(data=dfg, x=var, bins=30, kde=True)\n        plt.title(f'Distribution of {var}')\n    else:\n        sns.countplot(data=dfg, x=var)\n        plt.title(f'Frequency of {var}')\n    plt.tight_layout()\n\nplt.show()\ndfg[['ltmedmra', 'year5', 'dormant','red0']] = dfg[['ltmedmra', 'year5', 'dormant','red0']].astype('category')\n\n/tmp/ipykernel_5207/3543977266.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dfg[['ltmedmra', 'year5', 'dormant','red0']] = dfg[['ltmedmra', 'year5', 'dormant','red0']].astype('category')\ndonor_characteristics = ['ltmedmra', 'year5', 'gender']\ngeo_political_context = ['red0', 'perbush', 'nonlit']\nzip_code_demographics = ['median_hhincome', 'powner', 'psch_atlstba']\n\n# Combine into one list if needed\nselected_vars = donor_characteristics + geo_political_context + zip_code_demographics\n\nnum_vars = len(variables_to_plot)\nnum_cols = 3\nnum_rows = -(-num_vars // num_cols)  # Ceiling division\n\nplt.figure(figsize=(18, 5 * num_rows))\n\n# Plot distribution or frequency plots for selected_vars against 'amount'\nfor idx, var in enumerate(selected_vars, 1):\n    plt.subplot(num_rows, num_cols, idx)\n    if df[var].dtype in ['int64', 'float64', 'float32', 'int16', 'int8']:\n        sns.histplot(data=dfg, x=var, bins=10, kde=True)\n        plt.title(f' Plot of {var} vs Amount')\n    else:\n        sns.countplot(data=dfg, x=var)\n        plt.title(f'Frequency of {var}')\n    plt.xlabel(var)\n    plt.ylabel('Amount')\n    plt.tight_layout()\n\nplt.show()"
  },
  {
    "objectID": "projects/project 2/karlanlist.html#hypothesis-tests-to-confirm-if-non-outcome-variables-are-not-significantly-different-in-control-and-treatment-groups",
    "href": "projects/project 2/karlanlist.html#hypothesis-tests-to-confirm-if-non-outcome-variables-are-not-significantly-different-in-control-and-treatment-groups",
    "title": "Nitya's Website and Portfolio",
    "section": "Hypothesis tests to confirm if non-outcome variables are not significantly different in control and treatment groups",
    "text": "Hypothesis tests to confirm if non-outcome variables are not significantly different in control and treatment groups\nat 95% confidence level\n\ndf.columns\n\nIndex(['treatment', 'control', 'ratio', 'ratio2', 'ratio3', 'size', 'size25',\n       'size50', 'size100', 'sizeno', 'ask', 'askd1', 'askd2', 'askd3', 'ask1',\n       'ask2', 'ask3', 'amount', 'gave', 'amountchange', 'hpa', 'ltmedmra',\n       'freq', 'years', 'year5', 'mrm2', 'dormant', 'female', 'couple',\n       'state50one', 'nonlit', 'cases', 'statecnt', 'stateresponse',\n       'stateresponset', 'stateresponsec', 'stateresponsetminc', 'perbush',\n       'close25', 'red0', 'blue0', 'redcty', 'bluecty', 'pwhite', 'pblack',\n       'page18_39', 'ave_hh_sz', 'median_hhincome', 'powner', 'psch_atlstba',\n       'pop_propurban', 'gender'],\n      dtype='object')\n\n\nMRM2: Months since last donation\n\ntreatment_group_mrm2 = df[df['treatment'] == 1]['mrm2'].dropna()\ncontrol_group_mrm2 = df[df['control'] == 1]['mrm2'].dropna()\n\n# Calculate t-statistic\nmean_diff = treatment_group_mrm2.mean() - control_group_mrm2.mean()\nvar_treatment = treatment_group_mrm2.var(ddof=1)\nvar_control = control_group_mrm2.var(ddof=1)\nn_treatment = len(treatment_group_mrm2)\nn_control = len(control_group_mrm2)\n\npooled_se = ((var_treatment / n_treatment) + (var_control / n_control)) ** 0.5\nmanual_t_stat = mean_diff / pooled_se\n\nprint(f\"Manual T-statistic: {manual_t_stat:.4f}\")\n\nfrom scipy.stats import t\n\n# Degrees of freedom\ndf_degrees = n_treatment + n_control - 2\n\n# Critical value for 95% confidence level (two-tailed test)\ncritical_value = t.ppf(1 - 0.025, df_degrees)\n\nprint(f\"Critical value (95% confidence level): {critical_value:.4f}\")\n\n# Compare manual_t_stat against critical value\nif abs(manual_t_stat) &gt; critical_value:\n    print(\"Reject the null hypothesis: There is a statistically significant difference in mrm2 between treatment and control groups.\")\nelse:\n    print(\"Fail to reject the null hypothesis: There is no statistically significant difference in mrm2 between treatment and control groups.\")\n\nManual T-statistic: 0.1195\nCritical value (95% confidence level): 1.9600\nFail to reject the null hypothesis: There is no statistically significant difference in mrm2 between treatment and control groups.\n\n\n\n#crosss check with scipy stats\nfrom scipy.stats import ttest_ind\nfrom scipy.stats import t\n\nt_stat, p_value = ttest_ind(treatment_group_mrm2, control_group_mrm2, equal_var=False)\n\nprint(f\"T-statistic: {t_stat:.4f}\")\nprint(f\"P-value: {p_value:.4f}\")\n\n# Check significance at 95% confidence level\nif p_value &lt; 0.05:\n    print(\"The difference in mrm2 between treatment and control groups is statistically significant.\")\nelse:\n    print(\"The difference in mrm2 between treatment and control groups is not statistically significant.\")\n\nT-statistic: 0.1195\nP-value: 0.9049\nThe difference in mrm2 between treatment and control groups is not statistically significant.\n\n\nConfirm with linear regression:\nModel: mrm2 = β0 + β1 * treatment + ε\nThe coefficient β1 tells you the mean difference between treatment and control. The p-value on β1 tells you if this difference is statistically significant. Epsilon is the error term, which captures all other factors that might affect mrm2.\n\n#using linear regression to confirm\n\n\nimport statsmodels.api as sm\n\nX = df['treatment']  # Independent variable\ny = df['mrm2']       # Dependent variable\n\nX = sm.add_constant(X)\n\nmodel = sm.OLS(y, X, missing='drop').fit()\nprint(model.summary())\n\nprint(f\"T-value for treatment: {model.tvalues['treatment']:.4f}\")\nprint(f\"P-value for treatment: {model.pvalues['treatment']:.4f}\")\n\np_valuem = model.pvalues['treatment']\nt_valuem = model.tvalues['treatment']\n\n# Check the p-value of the treatment coefficient\nif model.pvalues['treatment'] &lt; 0.05:\n    print(\"The treatment effect on mrm2 is statistically significant.\")\nelse:\n    print(\"The treatment effect on mrm2 is not statistically significant.\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.905\nTime:                        19:24:38   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nT-value for treatment: 0.1195\nP-value for treatment: 0.9049\nThe treatment effect on mrm2 is not statistically significant.\n\n\nPerform hypothesis tests on other variable, picking few from each “bucket” of variables.\ndonor_characteristics = [‘ltmedmra’, ‘year5’, ‘gender’]\ngeo_political_context = [‘red0’, ‘perbush’, ‘nonlit’]\nzip_code_demographics = [‘median_hhincome’, ‘powner’, ‘psch_atlstba’]\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import t\n\n\ndonor_characteristics = ['freq', 'year5', 'female','mrm2']  \ngeo_political_context = ['red0', 'perbush', 'nonlit']\nzip_code_demographics = ['median_hhincome', 'powner', 'psch_atlstba']\n\nall_vars = donor_characteristics + geo_political_context + zip_code_demographics\n\n# Set significance level\nalpha = 0.05\n\n# Store results\nresults = []\n\n\n\nfor v in all_vars:\n    # Drop missing data\n    treatment = df[df['treatment'] == 1][v].dropna()\n    control = df[df['control'] == 1][v].dropna()\n\n    # Convert categorical variables to numeric if necessary\n    if treatment.dtype.name == 'category':\n        treatment = treatment.astype(int)\n    if control.dtype.name == 'category':\n        control = control.astype(int)\n\n    # Manual t-test\n    mean_diff = treatment.mean() - control.mean()\n    var_treatment = treatment.var(ddof=1)\n    var_control = control.var(ddof=1)\n    n_treatment = len(treatment)\n    n_control = len(control)\n\n    pooled_se = ((var_treatment / n_treatment) + (var_control / n_control))**0.5\n    manual_t_stat = mean_diff / pooled_se\n    df_degrees = n_treatment + n_control - 2\n    critical_value = t.ppf(1 - alpha/2, df_degrees)\n    manual_conclusion = \"Significant\" if abs(manual_t_stat) &gt; critical_value else \"Not Significant\"\n    \n    # Regression\n    X = df['treatment']\n    y = df[v]\n    X = sm.add_constant(X)\n\n    model = sm.OLS(y, X, missing='drop').fit(cov_type='HC1')\n\n\n    reg_t_stat = round(model.tvalues['treatment'], 4)\n    reg_p_value = round(model.pvalues['treatment'], 4)\n    reg_conclusion = \"Significant\" if reg_p_value &lt; alpha else \"Not Significant\"\n    \n\n    # Store the results\n    results.append({\n        \"Variable\": v,\n        \"Manual T-Stat\": round(manual_t_stat, 4),\n        \"Critical Value\": round(critical_value, 4),\n        \"Manual Test Conclusion\": manual_conclusion,\n        \"Regression T-Stat\": reg_t_stat,\n        \"Regression P-Value\": reg_p_value,\n        \"Regression Conclusion\": reg_conclusion\n    })\n\nresults_df = pd.DataFrame(results)\n\nresults_df\n\n\n\n\n\n\n\n\nVariable\nManual T-Stat\nCritical Value\nManual Test Conclusion\nRegression T-Stat\nRegression P-Value\nRegression Conclusion\n\n\n\n\n0\nfreq\n-0.1108\n1.96\nNot Significant\n-0.1108\n0.9117\nNot Significant\n\n\n1\nyear5\n-1.5627\n1.96\nNot Significant\n-1.5627\n0.1181\nNot Significant\n\n\n2\nfemale\n-1.7535\n1.96\nNot Significant\n-1.7535\n0.0795\nNot Significant\n\n\n3\nmrm2\n0.1195\n1.96\nNot Significant\n0.1195\n0.9049\nNot Significant\n\n\n4\nred0\n1.8773\n1.96\nNot Significant\n1.8773\n0.0605\nNot Significant\n\n\n5\nperbush\n2.7463\n1.96\nSignificant\n2.7463\n0.0060\nSignificant\n\n\n6\nnonlit\n1.7052\n1.96\nNot Significant\n1.7052\n0.0882\nNot Significant\n\n\n7\nmedian_hhincome\n-0.7433\n1.96\nNot Significant\n-0.7433\n0.4573\nNot Significant\n\n\n8\npowner\n0.1895\n1.96\nNot Significant\n0.1894\n0.8498\nNot Significant\n\n\n9\npsch_atlstba\n-1.8427\n1.96\nNot Significant\n-1.8427\n0.0654\nNot Significant\n\n\n\n\n\n\n\n\nprint(results_df.to_markdown(index=False))\n\n| Variable        |   Manual T-Stat |   Critical Value | Manual Test Conclusion   |   Regression T-Stat |   Regression P-Value | Regression Conclusion   |\n|:----------------|----------------:|-----------------:|:-------------------------|--------------------:|---------------------:|:------------------------|\n| freq            |         -0.1108 |             1.96 | Not Significant          |             -0.1108 |               0.9117 | Not Significant         |\n| year5           |         -1.5627 |             1.96 | Not Significant          |             -1.5627 |               0.1181 | Not Significant         |\n| female          |         -1.7535 |             1.96 | Not Significant          |             -1.7535 |               0.0795 | Not Significant         |\n| mrm2            |          0.1195 |             1.96 | Not Significant          |              0.1195 |               0.9049 | Not Significant         |\n| red0            |          1.8773 |             1.96 | Not Significant          |              1.8773 |               0.0605 | Not Significant         |\n| perbush         |          2.7463 |             1.96 | Significant              |              2.7463 |               0.006  | Significant             |\n| nonlit          |          1.7052 |             1.96 | Not Significant          |              1.7052 |               0.0882 | Not Significant         |\n| median_hhincome |         -0.7433 |             1.96 | Not Significant          |             -0.7433 |               0.4573 | Not Significant         |\n| powner          |          0.1895 |             1.96 | Not Significant          |              0.1894 |               0.8498 | Not Significant         |\n| psch_atlstba    |         -1.8427 |             1.96 | Not Significant          |             -1.8427 |               0.0654 | Not Significant         |\n\n\n\n# Generate markdown table\nmarkdown_table = results_df.to_markdown(index=False)\n\n# Read the original .qmd content\nwith open(\"index.qmd\", \"r\") as f:\n    qmd_text = f.read()\n\n# Replace the placeholder with the table\nqmd_text = qmd_text.replace(\"&lt;!-- INSERT_RESULTS_HERE --&gt;\", markdown_table)\n\n# Write back the updated file\nwith open(\"index.qmd\", \"w\") as f:\n    f.write(qmd_text)"
  },
  {
    "objectID": "projects/project 2/karlanlist.html#chairtable-contribution-made",
    "href": "projects/project 2/karlanlist.html#chairtable-contribution-made",
    "title": "Nitya's Website and Portfolio",
    "section": "Chairtable contribution made",
    "text": "Chairtable contribution made\n\n# Calculate the proportion of people who donated in each group\ntreatment_proportion = df[df['treatment'] == 1]['gave'].mean()\ncontrol_proportion = df[df['control'] == 1]['gave'].mean()\n\nplt.figure(figsize=(8, 6))\nax = sns.barplot(x=['Treatment', 'Control'], y=[treatment_proportion, control_proportion], palette='viridis')\n\nfor i, proportion in enumerate([treatment_proportion, control_proportion]):\n    plt.text(i, proportion + 0.001, f'{proportion:.3f}', ha='center', va='bottom', fontsize=10)\n\nplt.title('Proportion of People Who Donated by Group')\nplt.ylabel('Proportion')\nplt.xlabel('Group')\nplt.ylim(0, 0.05)\nplt.show()\n\n/tmp/ipykernel_5207/963862486.py:6: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.barplot(x=['Treatment', 'Control'], y=[treatment_proportion, control_proportion], palette='viridis')\n\n\n\n\n\n\n\n\n\n\n# Perform a bivariate linear regression\nX = df['treatment']  # Independent variable\ny = df['gave']       # Dependent variable (binary outcome)\n\nX = sm.add_constant(X)  # Add a constant for the regression\nmodel = sm.OLS(y, X, missing='drop').fit()\n\n# Print the regression summary\nprint(model.summary())\n\n# Extract the p-value and coefficient for interpretation\np_value = model.pvalues['treatment']\ncoef = model.params['treatment']\n\n# Interpretation\nif p_value &lt; 0.05:\n    print(f\"The treatment effect is statistically significant (p-value: {p_value:.4f}).\")\n    print(f\"The coefficient for treatment is {coef:.4f}, indicating that being in the treatment group increases the likelihood of making a charitable donation by {coef * 100:.2f} percentage points.\")\nelse:\n    print(f\"The treatment effect is not statistically significant (p-value: {p_value:.4f}).\")\n    print(\"There is no evidence to suggest that being in the treatment group affects the likelihood of making a charitable donation.\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        19:24:39   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nThe treatment effect is statistically significant (p-value: 0.0019).\nThe coefficient for treatment is 0.0042, indicating that being in the treatment group increases the likelihood of making a charitable donation by 0.42 percentage points.\n\n\n\nresults_bl = pd.DataFrame({\n    \"Variable\": model.params.index,\n    \"Coefficient\": model.params.values,\n    \"Standard Error\": model.bse.values,\n    \"t-Statistic\": model.tvalues.values,\n    \"p-Value\": model.pvalues.values,\n    \"CI Lower (95%)\": model.conf_int()[0].values,\n    \"CI Upper (95%)\": model.conf_int()[1].values\n})\n\n\nprint(results_bl.to_markdown(index=False))\nmarkdown_table = results_bl.to_markdown(index=False)\n\n# Read the original .qmd content\nwith open(\"index.qmd\", \"r\") as f:\n    qmd_text = f.read()\n\n# Replace the placeholder with the table\nqmd_text = qmd_text.replace(\"&lt;!-- INSERT_RESULTSb1_HERE --&gt;\", markdown_table)\n\n# Write back the updated file\nwith open(\"index.qmd\", \"w\") as f:\n    f.write(qmd_text)\n\n| Variable   |   Coefficient |   Standard Error |   t-Statistic |     p-Value |   CI Lower (95%) |   CI Upper (95%) |\n|:-----------|--------------:|-----------------:|--------------:|------------:|-----------------:|-----------------:|\n| const      |    0.0178582  |       0.00110068 |      16.2246  | 4.77903e-59 |       0.0157009  |       0.0200156  |\n| treatment  |    0.00418035 |       0.00134791 |       3.10136 | 0.0019274   |       0.00153844 |       0.00682227 |\n\n\n\nProbit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control\n\nimport statsmodels.api as sm\n\nX = df['treatment']  # Independent variable\ny = df['gave']       # Dependent variable (binary outcome)\n\nX = sm.add_constant(X)\n\nprobit_model = sm.Probit(y, X, missing='drop').fit()\n\nprint(probit_model.summary())\n\np_value_probit = probit_model.pvalues['treatment']\ncoef_probit = probit_model.params['treatment']\n\n# Interpretation\nif p_value_probit &lt; 0.05:\n    print(f\"The treatment effect is statistically significant (p-value: {p_value_probit:.4f}).\")\n    print(f\"The coefficient for treatment is {coef_probit:.4f}, indicating that being in the treatment group has a significant effect on the likelihood of making a charitable donation.\")\nelse:\n    print(f\"The treatment effect is not statistically significant (p-value: {p_value_probit:.4f}).\")\n    print(\"There is no evidence to suggest that being in the treatment group affects the likelihood of making a charitable donation.\")\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        19:24:40   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\nThe treatment effect is statistically significant (p-value: 0.0019).\nThe coefficient for treatment is 0.0868, indicating that being in the treatment group has a significant effect on the likelihood of making a charitable donation.\n\n\n\nresults_pr = pd.DataFrame({\n    \"Variable\": model.params.index,\n    \"Coefficient\": model.params.values,\n    \"Standard Error\": model.bse.values,\n    \"t-Statistic\": model.tvalues.values,\n    \"p-Value\": model.pvalues.values,\n    \"CI Lower (95%)\": model.conf_int()[0].values,\n    \"CI Upper (95%)\": model.conf_int()[1].values\n})\n\n\nprint(results_pr.to_markdown(index=False))\nmarkdown_table = results_pr.to_markdown(index=False)\n\n# Read the original .qmd content\nwith open(\"index.qmd\", \"r\") as f:\n    qmd_text = f.read()\n\n# Replace the placeholder with the table\nqmd_text = qmd_text.replace(\"&lt;!-- INSERT_RESULTSpr_HERE --&gt;\", markdown_table)\n\n# Write back the updated file\nwith open(\"index.qmd\", \"w\") as f:\n    f.write(qmd_text)\n\n| Variable   |   Coefficient |   Standard Error |   t-Statistic |     p-Value |   CI Lower (95%) |   CI Upper (95%) |\n|:-----------|--------------:|-----------------:|--------------:|------------:|-----------------:|-----------------:|\n| const      |    0.0178582  |       0.00110068 |      16.2246  | 4.77903e-59 |       0.0157009  |       0.0200156  |\n| treatment  |    0.00418035 |       0.00134791 |       3.10136 | 0.0019274   |       0.00153844 |       0.00682227 |\n\n\n\n\nDifferences between Match Rates\n\nprint(\"Unique values in 'ratio':\", df['ratio'].unique())\nprint(\"Unique values in 'ratio2':\", df['ratio2'].unique())\nprint(\"Unique values in 'ratio3':\", df['ratio3'].unique())\n\nUnique values in 'ratio': ['Control', 1, 2, 3]\nCategories (4, object): ['Control' &lt; 1 &lt; 2 &lt; 3]\nUnique values in 'ratio2': [0, 1]\nCategories (2, int8): [0, 1]\nUnique values in 'ratio3': [0, 1]\nCategories (2, int8): [0, 1]\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Create group masks\nis_1to1 = (df['treatment'] == 1) & (df['ratio2'] == 0) & (df['ratio3'] == 0)\nis_2to1 = df['ratio2'] == 1\nis_3to1 = df['ratio3'] == 1\n\n# Get gave outcomes for each group\ngave_1to1 = df[is_1to1]['gave'].dropna()\ngave_2to1 = df[is_2to1]['gave'].dropna()\ngave_3to1 = df[is_3to1]['gave'].dropna()\n\n# Run t-tests\nt_stat_21, p_val_21 = ttest_ind(gave_2to1, gave_1to1, equal_var=False)\nt_stat_31, p_val_31 = ttest_ind(gave_3to1, gave_1to1, equal_var=False)\nt_stat_32, p_val_32 = ttest_ind(gave_3to1, gave_2to1, equal_var=False)\n\n# Print results\nprint(f\"2:1 vs 1:1 → t = {t_stat_21:.4f}, p = {p_val_21:.4f}\")\nprint(f\"3:1 vs 1:1 → t = {t_stat_31:.4f}, p = {p_val_31:.4f}\")\nprint(f\"3:1 vs 2:1 → t = {t_stat_32:.4f}, p = {p_val_32:.4f}\")\n\n2:1 vs 1:1 → t = 0.9650, p = 0.3345\n3:1 vs 1:1 → t = 1.0150, p = 0.3101\n3:1 vs 2:1 → t = 0.0501, p = 0.9600\n\n\n\nfrom scipy.stats import t\n\nalpha = 0.05  # for 95% confidence\nresults = []\n\n# Group definitions\nis_1to1 = (df['treatment'] == 1) & (df['ratio2'] == 0) & (df['ratio3'] == 0)\nis_2to1 = df['ratio2'] == 1\nis_3to1 = df['ratio3'] == 1\n\n# Pairings: label, group1, group2\npairings = [\n    (\"2:1 vs 1:1\", df[is_2to1]['gave'].dropna(), df[is_1to1]['gave'].dropna()),\n    (\"3:1 vs 1:1\", df[is_3to1]['gave'].dropna(), df[is_1to1]['gave'].dropna()),\n    (\"3:1 vs 2:1\", df[is_3to1]['gave'].dropna(), df[is_2to1]['gave'].dropna())\n]\n\nfor label, group1, group2 in pairings:\n    mean1 = group1.mean()\n    mean2 = group2.mean()\n    mean_diff = mean1 - mean2\n    var1 = group1.var(ddof=1)\n    var2 = group2.var(ddof=1)\n    n1 = len(group1)\n    n2 = len(group2)\n\n    pooled_se = ((var1 / n1) + (var2 / n2)) ** 0.5\n    manual_t_stat = mean_diff / pooled_se\n    df_degrees = n1 + n2 - 2\n    critical_value = t.ppf(1 - alpha/2, df_degrees)\n    conclusion = \"Significant\" if abs(manual_t_stat) &gt; critical_value else \"Not Significant\"\n\n    results.append({\n        \"Comparison\": label,\n        \"Group 1 Mean Donation Rate\": round(mean1 * 100, 2),  # Convert to %\n        \"Group 2 Mean Donation Rate\": round(mean2 * 100, 2),\n        \"Mean Diff (pp)\": round(mean_diff * 100, 2),\n        \"T-Statistic\": round(manual_t_stat, 4),\n        \"Critical Value (±)\": round(critical_value, 4),\n        \"Conclusion\": conclusion\n    })\n\n# Display results\nimport pandas as pd\nresults1_df = pd.DataFrame(results)\nprint(results1_df.to_markdown(index=False))\n\n| Comparison   |   Group 1 Mean Donation Rate |   Group 2 Mean Donation Rate |   Mean Diff (pp) |   T-Statistic |   Critical Value (±) | Conclusion      |\n|:-------------|-----------------------------:|-----------------------------:|-----------------:|--------------:|---------------------:|:----------------|\n| 2:1 vs 1:1   |                         2.26 |                         2.07 |             0.19 |        0.965  |               1.9601 | Not Significant |\n| 3:1 vs 1:1   |                         2.27 |                         2.07 |             0.2  |        1.015  |               1.9601 | Not Significant |\n| 3:1 vs 2:1   |                         2.27 |                         2.26 |             0.01 |        0.0501 |               1.9601 | Not Significant |\n\n\n\n# Generate markdown table\nmarkdown_table = results1_df.to_markdown(index=False)\n\n# Read the original .qmd content\nwith open(\"index.qmd\", \"r\") as f:\n    qmd_text = f.read()\n\n# Replace the placeholder with the table\nqmd_text = qmd_text.replace(\"&lt;!-- INSERT_RESULTS1_HERE --&gt;\", markdown_table)\n\n# Write back the updated file\nwith open(\"index.qmd\", \"w\") as f:\n    f.write(qmd_text)\n\n\nAssess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision\n\n# Create the ratio1 variable\ndf['ratio1'] = ((df['ratio2'] == 0) & (df['ratio3'] == 0)).astype(int)\n\nX = df[['ratio1', 'ratio2', 'ratio3']]  # Independent variables\ny = df['gave']  # Dependent variable\n\nX = sm.add_constant(X)  # Add a constant term for the regression\nmodel = sm.OLS(y, X, missing='drop').fit()\n\nprint(model.summary())\n\ncoefficients = model.params\np_values = model.pvalues\n\nfor var in ['ratio1', 'ratio2', 'ratio3']:\n    if p_values[var] &lt; 0.05:\n        print(f\"The coefficient for {var} is {coefficients[var]:.4f}, which is statistically significant (p-value: {p_values[var]:.4f}).\")\n    else:\n        print(f\"The coefficient for {var} is {coefficients[var]:.4f}, which is not statistically significant (p-value: {p_values[var]:.4f}).\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     2.743\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):             0.0415\nTime:                        19:24:41   Log-Likelihood:                 26629.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.321e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       1.229e+10   1.54e+11      0.080      0.936   -2.89e+11    3.14e+11\nratio1     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\nratio2     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\nratio3     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\n==============================================================================\nOmnibus:                    59815.676   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317583.266\nSkew:                           6.741   Prob(JB):                         0.00\nKurtosis:                      46.443   Cond. No.                     5.80e+14\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 2.13e-25. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\nThe coefficient for ratio1 is -12293201518.4371, which is not statistically significant (p-value: 0.9363).\nThe coefficient for ratio2 is -12293201518.4334, which is not statistically significant (p-value: 0.9363).\nThe coefficient for ratio3 is -12293201518.4333, which is not statistically significant (p-value: 0.9363).\n\n\n\n#The results show clear signs of a severe multicollinearity or design matrix error, likely caused by including all three dummy variables (ratio1, ratio2, ratio3) without dropping a reference group. Since the three dummies are mutually exclusive and exhaustive (they sum to 1), including all of them with a constant creates a perfect linear dependency, which leads to a singular matrix and unreliable coefficient estimates. \n# To fix this, I omit one of the ratio dummies (e.g., drop ratio1) so that the remaining coefficients (ratio2 and ratio3) are interpreted relative to the 1:1 match group. \n\nimport statsmodels.api as sm\n\n# Make sure 'gave' is numeric\ny = df['gave'].astype(float)\n\n# Only include ratio2 and ratio3 — 1:1 (ratio1) is the reference group\nX = df[['ratio2', 'ratio3']]\n\n# Add a constant (intercept)\nX = sm.add_constant(X)\n\n# Fit the linear regression model\nmodel = sm.OLS(y, X, missing='drop').fit()\n\n# Print summary\nprint(model.summary())\n\n# Interpret the coefficients\ncoefficients = model.params\np_values = model.pvalues\n\nfor var in ['ratio2', 'ratio3']:\n    if p_values[var] &lt; 0.05:\n        print(f\"The coefficient for {var} is {coefficients[var]:.4f}, which is statistically significant (p-value: {p_values[var]:.4f}).\")\n    else:\n        print(f\"The coefficient for {var} is {coefficients[var]:.4f}, which is not statistically significant (p-value: {p_values[var]:.4f}).\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     4.117\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):             0.0163\nTime:                        19:24:41   Log-Likelihood:                 26629.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50080   BIC:                        -5.323e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0190      0.001     22.306      0.000       0.017       0.021\nratio2         0.0036      0.002      2.269      0.023       0.000       0.007\nratio3         0.0037      0.002      2.332      0.020       0.001       0.007\n==============================================================================\nOmnibus:                    59815.856   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317637.927\nSkew:                           6.741   Prob(JB):                         0.00\nKurtosis:                      46.443   Cond. No.                         3.16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nThe coefficient for ratio2 is 0.0036, which is statistically significant (p-value: 0.0233).\nThe coefficient for ratio3 is 0.0037, which is statistically significant (p-value: 0.0197).\n\n\n\nresults_r = pd.DataFrame({\n    \"Variable\": model.params.index,\n    \"Coefficient\": model.params.values,\n    \"Standard Error\": model.bse.values,\n    \"t-Statistic\": model.tvalues.values,\n    \"p-Value\": model.pvalues.values,\n    \"CI Lower (95%)\": model.conf_int()[0].values,\n    \"CI Upper (95%)\": model.conf_int()[1].values\n})\n\n\nprint(results_r.to_markdown(index=False))\nmarkdown_table = results_r.to_markdown(index=False)\n\n# Read the original .qmd content\nwith open(\"index.qmd\", \"r\") as f:\n    qmd_text = f.read()\n\n# Replace the placeholder with the table\nqmd_text = qmd_text.replace(\"&lt;!-- INSERT_RESULTSr_HERE --&gt;\", markdown_table)\n\n# Write back the updated file\nwith open(\"index.qmd\", \"w\") as f:\n    f.write(qmd_text)\n\n| Variable   |   Coefficient |   Standard Error |   t-Statistic |      p-Value |   CI Lower (95%) |   CI Upper (95%) |\n|:-----------|--------------:|-----------------:|--------------:|-------------:|-----------------:|-----------------:|\n| const      |    0.0190151  |      0.000852479 |      22.3056  | 1.11719e-109 |      0.0173442   |       0.020686   |\n| ratio2     |    0.00361828 |      0.00159454  |       2.26917 | 0.023262     |      0.000492971 |       0.00674359 |\n| ratio3     |    0.0037183  |      0.00159479  |       2.33153 | 0.0197294    |      0.000592493 |       0.00684411 |\n\n\n\n\nCalculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n# Identify match groups\nis_1to1 = (df['treatment'] == 1) & (df['ratio2'] == 0) & (df['ratio3'] == 0)\nis_2to1 = df['ratio2'] == 1\nis_3to1 = df['ratio3'] == 1\n\n# donation rates\nrate_1to1 = df[is_1to1]['gave'].mean()\nrate_2to1 = df[is_2to1]['gave'].mean()\nrate_3to1 = df[is_3to1]['gave'].mean()\n\ndiff_21_vs_11 = rate_2to1 - rate_1to1\ndiff_31_vs_21 = rate_3to1 - rate_2to1\n\nprint(f\"2:1 vs 1:1 response rate difference: {diff_21_vs_11:.4f}\")\nprint(f\"3:1 vs 2:1 response rate difference: {diff_31_vs_21:.4f}\")\n\n# difference from coefficients from the regression\ncoef_2to1 = coefficients['ratio2']\ncoef_3to1 = coefficients['ratio3']\n\ndiff_coef_1to1_2to1 = coef_2to1  # Coefficient for ratio2 represents the difference from 1:1\ndiff_coef_2to1_3to1 = coef_3to1 - coef_2to1  # Difference between coefficients for ratio3 and ratio2\n\nprint(f\"Response rate difference from coefficients (2:1 - 1:1): {diff_coef_1to1_2to1:.4f}\")\nprint(f\"Response rate difference from coefficients (3:1 - 2:1): {diff_coef_2to1_3to1:.4f}\")\n\n2:1 vs 1:1 response rate difference: 0.0019\n3:1 vs 2:1 response rate difference: 0.0001\nResponse rate difference from coefficients (2:1 - 1:1): 0.0036\nResponse rate difference from coefficients (3:1 - 2:1): 0.0001\n\n\n\n\n\nSize of Charitable Contribution\n\nCalculate a t-test of the donation amount on the treatment status\nIncluding donation values where gave = 0 i.e. donation = 0\n\nfrom scipy.stats import t\n\n# Select donation amount by group\ntreatment_group_amount = df[df['treatment'] == 1]['amount'].dropna()\ncontrol_group_amount = df[df['treatment'] == 0]['amount'].dropna()\n\n# Basic stats\nmean_diff = treatment_group_amount.mean() - control_group_amount.mean()\nvar_treatment = treatment_group_amount.var(ddof=1)\nvar_control = control_group_amount.var(ddof=1)\nn_treatment = len(treatment_group_amount)\nn_control = len(control_group_amount)\n\n# Pooled standard error\npooled_se = ((var_treatment / n_treatment) + (var_control / n_control)) ** 0.5\n\n# Manual t-statistic\nmanual_t_stat = mean_diff / pooled_se\nprint(f\"Manual T-statistic: {manual_t_stat:.4f}\")\n\n# Degrees of freedom (for equal variance t-test)\ndf_degrees = n_treatment + n_control - 2\n\n# Critical t value for 95% confidence (two-tailed)\ncritical_value = t.ppf(1 - 0.025, df_degrees)\nprint(f\"Critical value (±): {critical_value:.4f}\")\n\n# Conclusion\nif abs(manual_t_stat) &gt; critical_value:\n    print(\"Result: Statistically significant difference in donation amount.\")\nelse:\n    print(\"Result: No statistically significant difference in donation amount.\")\n\nManual T-statistic: 1.9182\nCritical value (±): 1.9600\nResult: No statistically significant difference in donation amount.\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Extract donation amounts for treatment and control groups\ntreatment_donations = df[df['treatment'] == 1]['amount'].dropna()\ncontrol_donations = df[df['control'] == 1]['amount'].dropna()\n\n# Perform t-test\nt_stat, p_value = ttest_ind(treatment_donations, control_donations, equal_var=False)\n\nprint(f\"T-statistic: {t_stat:.4f}\")\nprint(f\"P-value: {p_value:.4f}\")\n\nmean_treatment = treatment_donations.mean()\nmean_control = control_donations.mean()\nprint(f\"Mean donation (treatment group): ${mean_treatment:.2f}\")\nprint(f\"Mean donation (control group):   ${mean_control:.2f}\")\n\n# Check significance at 95% confidence level\nif p_value &lt; 0.05:\n    print(\"The difference in donation amounts between treatment and control groups is statistically significant.\")\nelse:\n    print(\"The difference in donation amounts between treatment and control groups is not statistically significant.\")\n\nT-statistic: 1.9183\nP-value: 0.0551\nMean donation (treatment group): $0.97\nMean donation (control group):   $0.81\nThe difference in donation amounts between treatment and control groups is not statistically significant.\n\n\nOnly including donation values where gave = 1 i.e. donation &gt; 0\n\nfrom scipy.stats import ttest_ind\n\n# Extract donation amounts for treatment and control groups\ntreatment_donations = df[(df['treatment'] == 1) & (df['gave'] == 1)]['amount'].dropna()\ncontrol_donations = df[(df['control'] == 1) & (df['gave'] == 1)]['amount'].dropna()\n\n# Perform t-test\nt_stat, p_value = ttest_ind(treatment_donations, control_donations, equal_var=False)\n\nprint(f\"T-statistic: {t_stat:.4f}\")\nprint(f\"P-value: {p_value:.4f}\")\n\nmean_treatment = treatment_donations.mean()\nmean_control = control_donations.mean()\nprint(f\"Mean donation (treatment group): ${mean_treatment:.2f}\")\nprint(f\"Mean donation (control group):   ${mean_control:.2f}\")\n\n# Check significance at 95% confidence level\nif p_value &lt; 0.05:\n    print(\"The difference in donation amounts between treatment and control groups is statistically significant.\")\nelse:\n    print(\"The difference in donation amounts between treatment and control groups is not statistically significant.\")\n\nT-statistic: -0.5846\nP-value: 0.5590\nMean donation (treatment group): $43.87\nMean donation (control group):   $45.54\nThe difference in donation amounts between treatment and control groups is not statistically significant.\n\n\n\n#using bivariate regression \n\ndonors = df[df['gave'] == 1].copy()\n\ny = donors['amount'].astype(float)\nX = sm.add_constant(donors['treatment'])  # Treatment: 1 = treatment group, 0 = control\n\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary())\n\ncoef = model.params['treatment']\np_val = model.pvalues['treatment']\nmean_treat = donors[donors['treatment'] == 1]['amount'].mean()\nmean_control = donors[donors['treatment'] == 0]['amount'].mean()\n\nprint(f\"Mean donation (treatment group): ${mean_treat:.2f}\")\nprint(f\"Mean donation (control group):   ${mean_control:.2f}\")\nprint(f\"Coefficient (treatment): {coef:.4f}, p-value: {p_val:.4f}\")\n\nif p_val &lt; 0.05:\n    print(\"The treatment has a statistically significant effect on donation amount (among donors).\")\nelse:\n    print(\"There is no statistically significant difference in donation amount between treatment and control groups (among donors).\")\n\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.561\nTime:                        19:24:41   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nMean donation (treatment group): $43.87\nMean donation (control group):   $45.54\nCoefficient (treatment): -1.6684, p-value: 0.5615\nThere is no statistically significant difference in donation amount between treatment and control groups (among donors).\n\n\n\nresults_d = pd.DataFrame({\n    \"Variable\": model.params.index,\n    \"Coefficient\": model.params.values,\n    \"Standard Error\": model.bse.values,\n    \"t-Statistic\": model.tvalues.values,\n    \"p-Value\": model.pvalues.values,\n    \"CI Lower (95%)\": model.conf_int()[0].values,\n    \"CI Upper (95%)\": model.conf_int()[1].values\n})\n\n\nprint(results_d.to_markdown(index=False))\nmarkdown_table = results_d.to_markdown(index=False)\n\n# Read the original .qmd content\nwith open(\"index.qmd\", \"r\") as f:\n    qmd_text = f.read()\n\n# Replace the placeholder with the table\nqmd_text = qmd_text.replace(\"&lt;!-- INSERT_RESULTSd_HERE --&gt;\", markdown_table)\n\n# Write back the updated file\nwith open(\"index.qmd\", \"w\") as f:\n    f.write(qmd_text)\n\n| Variable   |   Coefficient |   Standard Error |   t-Statistic |     p-Value |   CI Lower (95%) |   CI Upper (95%) |\n|:-----------|--------------:|-----------------:|--------------:|------------:|-----------------:|-----------------:|\n| const      |      45.5403  |          2.42338 |     18.7921   | 5.47358e-68 |         40.785   |         50.2956  |\n| treatment  |      -1.66839 |          2.87238 |     -0.580839 | 0.561476    |         -7.30477 |          3.96799 |\n\n\n\n# Check if control = 1 for all rows where treatment = 0\nall_control_correct = (df[df['treatment'] == 0]['control'] == 1).all()\n\nif all_control_correct:\n    print(\"For all rows where treatment = 0, control = 1.\")\nelse:\n    print(\"There are rows where treatment = 0 but control is not 1.\")\n\nFor all rows where treatment = 0, control = 1.\n\n\n\n# Check if treatment = 1 for all rows where control = 0\nall_control_correct = (df[df['control'] == 0]['treatment'] == 1).all()\n\nif all_control_correct:\n    print(\"For all rows where c = 0, t = 1.\")\nelse:\n    print(\"There are rows where c = 0 but t is not 1.\")\n\nFor all rows where c = 0, t = 1.\n\n\n\n\nMake two plots: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot\n\n# Filter donation amounts for treatment and control groups where donations were made (gave = 1)\ntreatment_donations = df[(df['treatment'] == 1) & (df['gave'] == 1)]['amount']\ncontrol_donations = df[(df['control'] == 1) & (df['gave'] == 1)]['amount']\n\n# Calculate means for annotation\nmean_treatment = treatment_donations.mean()\nmean_control = control_donations.mean()\n\n# Plot for treatment group\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.histplot(treatment_donations, bins=30, kde=False, color='blue', alpha=0.7)\nplt.axvline(mean_treatment, color='red', linestyle='--', label=f'Mean: ${mean_treatment:.2f}')\nplt.title('Donation Amounts - Treatment Group')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.ylim(0, 300)  # Set y-axis scale\nplt.legend()\n\n# Plot for control group\nplt.subplot(1, 2, 2)\nsns.histplot(control_donations, bins=30, kde=False, color='green', alpha=0.7)\nplt.axvline(mean_control, color='red', linestyle='--', label=f'Mean: ${mean_control:.2f}')\nplt.title('Donation Amounts - Control Group')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.ylim(0, 300)  # Set y-axis scale\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\nLaw of Large Numbers\nSimulating 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. I then calculate a vector of 10,000 differences, and then plot the cumulative average of that vector of differences.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# True probabilities\np_control = 0.018 #do not get any charitable match\np_treatment = 0.022 #get a charitable match of any size\n\nn = 10000\n\n# Simulate 10,000 Bernoulli draws from each group\ncontrol = np.random.binomial(1, p_control, n)\ntreatment = np.random.binomial(1, p_treatment, n)\n\n# Compute differences between each draw (pairwise)\ndifferences = treatment - control  # each element is 0, +1, or -1\n\n# Cumulative average of the differences\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n + 1)\n\n\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff, label=\"Cumulative Average of Differences\", color='blue')\nplt.axhline(0.004, color='red', linestyle='--', label=\"True Treatment Effect (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.title(\"Simulation Demonstrating Law of Large Numbers\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThis average is “noisey” when only averaging a few numbers, but “settles down” and approximate the treatment effect (0.004 = 0.022 - 0.018) as the sample size gets large. But in this run, it converges slightly above the true treatment effect. Let’s try another run.\n\n\n\n# True probabilities\np_control = 0.018 #do not get any charitable match\np_treatment = 0.022 #get a charitable match of any size\n\nn = 10000\n\n# Simulate 10,000 Bernoulli draws from each group\ncontrol = np.random.binomial(1, p_control, n)\ntreatment = np.random.binomial(1, p_treatment, n)\n\n# Compute differences between each draw (pairwise)\ndifferences = treatment - control  # each element is 0, +1, or -1\n\n# Cumulative average of the differences\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n + 1)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff, label=\"Cumulative Average of Differences\", color='blue')\nplt.axhline(0.004, color='red', linestyle='--', label=\"True Treatment Effect (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.title(\"Simulation Demonstrating Law of Large Numbers\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nI make 4 histograms at sample sizes 50, 200, 500, and 1000.\nTo do this for a sample size of e.g. 50, I take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws.\nThen, I repeat that process 999 more times so that I have 1000 averages. Lastly, I plot the histogram of those averages, repeating for the other 3 histograms.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\n# Create subplots\nfig, axs = plt.subplots(1, 4, figsize=(20, 5), sharey=True)\n\nfor i, n in enumerate(sample_sizes):\n    mean_diffs = []\n    \n    for _ in range(num_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        mean_diffs.append(diff)\n    \n    # Plot histogram\n    axs[i].hist(mean_diffs, bins=30, color='skyblue', edgecolor='black')\n    axs[i].axvline(0.004, color='red', linestyle='--', label='True Treatment Effect')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Avg. Treatment Effect\")\n    axs[i].legend()\n\naxs[0].set_ylabel(\"Frequency\")\nplt.suptitle(\"Demonstrating the Central Limit Theorem\", fontsize=16)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()"
  },
  {
    "objectID": "projects/project 1/index.html",
    "href": "projects/project 1/index.html",
    "title": "Predicting Late Delivery Risk for a Sport Retail Business",
    "section": "",
    "text": "This project analyzes and predicts late delivery trends in a sports retail business, identifying key factors like shipping mode, order location, and payment method using logistic regression. It provides actionable insights via interactive dashboards to improve delivery performance.\nGithub Link here.\n\n\nThis project, titled “Identifying Risk of Late Deliveries in a Sports Retail Business,” focuses on analyzing and mitigating late deliveries in a sports retail business operating across the Americas. The business fulfills over 21,000 orders annually, generating $42 million in sales, with products sourced from the USA and Puerto Rico and sold across 22 countries.\nSkills used: Python, Streamlit, Data visualization, Scikit-learn, Feature Engineering, RandomForest, Logistic Regression"
  },
  {
    "objectID": "projects/project 1/index.html#sub-header",
    "href": "projects/project 1/index.html#sub-header",
    "title": "Predicting Late Delivery Risk for a Sport Retail Business",
    "section": "",
    "text": "This project, titled “Identifying Risk of Late Deliveries in a Sports Retail Business,” focuses on analyzing and mitigating late deliveries in a sports retail business operating across the Americas. The business fulfills over 21,000 orders annually, generating $42 million in sales, with products sourced from the USA and Puerto Rico and sold across 22 countries.\nSkills used: Python, Streamlit, Data visualization, Scikit-learn, Feature Engineering, RandomForest, Logistic Regression"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nitya Kowsalya Vootla",
    "section": "",
    "text": "Call me the KPI Knight 🦸🏿‍♀️I achieve business goals through strategic insights, scalable solutions, and cross-functional execution. I build platforms, analytical tools, and products hat help businesses optimize processes, mitigate risks, enhance customer experience, and drive sustainable growth.\n🦸🏿‍♀️At TikTok, I launched a risk intelligence platform to ensure a safer consumer shopping experience and make uncovering risks a 50% more efficient process across 12 global teams.\n🦸🏿‍♀️At Glints, a high-growth Southeast Asian startup, I spearheaded the implementation of CRM software, increasing lead conversion by 40%, and launched a B2B client service ticketing system that improved customer issue resolution by 52%.\n🦸🏿‍♀️At Halliburton, I built more efficient project management tools that optimized supply chain analytics and tracking processes, achieving $200K in cost savings within my first six months in a full-time role.\n🦸🏿‍♀️ At UCSD, I work extensively on building and tuning LLM powered Assistants, as well as advanced statistical modeling and machine learning methods to optimize fraud analytics and customer analytics.\nArmed with a Master’s in Business Analytics from UC San Diego, I specialize in translating complex data into actionable strategies to build tools and products. Whether it’s driving customer satisfaction, refining operational efficiency, or scaling analytics capabilities, I bring resilience and a builder’s precision to every project. Beyond my work, I enjoy volunteering as a student consultant for non-profits, running, and creating vegan dishes for my friends.\nLet’s connect if you’re looking for a results-driven, data-savvy creative to augment your platforms and products."
  },
  {
    "objectID": "projects/project 2/index.html",
    "href": "projects/project 2/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\n\n\nIn their 2007 study, Karlan and List implemented a large-scale natural field experiment to investigate how the match rate of matching grants influence charitable giving behavior. They employ a direct mail solicitation to explore whether and the extent to which, “price” i.e. cost to the donor of providing one dollar’s worth of public good to a nonprofit, is crucial in charitable fundraising.\nThe experiment involved 50,083 previous donors who had contributed, at least once since 1991, to a chosen liberal nonprofit organization in the United States. All individuals received one of the variations of a four page fundraising letter and reply card via direct mail, a standard channel used large charities in the US to ensure practical interest and high external validity. Furthermore, because the organization is politically engaged, this allows the team to explore heterogeneous treatment effects, particularly in how donors from “red” and “blue” states responded to the match offers.\nParticipants were randomly assigned to either a control group (approximately one-third of the sample) or a treatment group (the remaining two-thirds). The control group received a letter following the organization’s conventional format and a reply card with a large logo of the organization, while the treatment group received a letter that included an announcement on a “concerned fellow member” offering to match their donation, with a reply card that included the details of the match in bold font.\nWithin the treatment group, the experiment further varied the characteristics of the matching grant along three dimensions with equal probability:\n\nFirst, the matching ratio was randomized to be either $1:$1, $2:$1, or $3:$1, meaning that for each dollar donated, the organization would receive an additional $1, $2, or $3, respectively. This allowed the researchers to test whether increasing the perceived “value” of a donation would lead to higher giving.\nSecond, the maximum size of the matching grant pool was varied, with donors being told it was capped at $25,000, $50,000, $100,000, or left unstated. This tested whether the size of the match fund—possibly perceived as a signal of the urgency or importance of the campaign—influenced donor behavior.\nThird, the suggested donation amount was tailored to each donor’s prior giving history, using either the same amount as their highest previous contribution, or scaling it up by 1.25 or 1.5 times. The chosen example was used in the matching paragraph to illustrate the impact of their gift under the match.\n\nThe design of the experiment was intended not only to evaluate the overall impact of matching grants but also to probe how different configurations of the matching appeal might influence giving, by understanding the social behavioral mechanisms behind charitable donations like conformity, social norms, and reciprocity.\nThe key hypotheses in this experiment are:\n\nPresence of a Matching Grant Increases Giving: Donors are more likely to contribute when a matching grant is offered, compared to when no match is offered.\nHigher Match Ratios Lead to Higher Giving: Increasing the match ratio (e.g., from $1:$1 to $2:$1 or $3:$1) will further increase donation rates and total contributions by making the “price” of giving lower.\nLarger Matching Grant Pools Increase Giving: Announcing a larger maximum size of the matching fund (e.g., $100,000 vs. $25,000) will lead to greater donations due to perceived urgency, credibility, or impact.\nHigher Suggested Donation Amounts Influence Giving: Presenting donors with higher suggested donation amounts will lead to larger contributions, possibly by anchoring their perception of a “typical” or expected gift.\nDonor Responsiveness to Matching Grants Varies by Political Context: Donors living in different political environments (e.g., red vs. blue states) will respond differently to the match offer, potentially due to identity, perceived relevance, or local norms.\n\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project 2/index.html#introduction",
    "href": "projects/project 2/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\n\n\nIn their 2007 study, Karlan and List implemented a large-scale natural field experiment to investigate how the match rate of matching grants influence charitable giving behavior. They employ a direct mail solicitation to explore whether and the extent to which, “price” i.e. cost to the donor of providing one dollar’s worth of public good to a nonprofit, is crucial in charitable fundraising.\nThe experiment involved 50,083 previous donors who had contributed, at least once since 1991, to a chosen liberal nonprofit organization in the United States. All individuals received one of the variations of a four page fundraising letter and reply card via direct mail, a standard channel used large charities in the US to ensure practical interest and high external validity. Furthermore, because the organization is politically engaged, this allows the team to explore heterogeneous treatment effects, particularly in how donors from “red” and “blue” states responded to the match offers.\nParticipants were randomly assigned to either a control group (approximately one-third of the sample) or a treatment group (the remaining two-thirds). The control group received a letter following the organization’s conventional format and a reply card with a large logo of the organization, while the treatment group received a letter that included an announcement on a “concerned fellow member” offering to match their donation, with a reply card that included the details of the match in bold font.\nWithin the treatment group, the experiment further varied the characteristics of the matching grant along three dimensions with equal probability:\n\nFirst, the matching ratio was randomized to be either $1:$1, $2:$1, or $3:$1, meaning that for each dollar donated, the organization would receive an additional $1, $2, or $3, respectively. This allowed the researchers to test whether increasing the perceived “value” of a donation would lead to higher giving.\nSecond, the maximum size of the matching grant pool was varied, with donors being told it was capped at $25,000, $50,000, $100,000, or left unstated. This tested whether the size of the match fund—possibly perceived as a signal of the urgency or importance of the campaign—influenced donor behavior.\nThird, the suggested donation amount was tailored to each donor’s prior giving history, using either the same amount as their highest previous contribution, or scaling it up by 1.25 or 1.5 times. The chosen example was used in the matching paragraph to illustrate the impact of their gift under the match.\n\nThe design of the experiment was intended not only to evaluate the overall impact of matching grants but also to probe how different configurations of the matching appeal might influence giving, by understanding the social behavioral mechanisms behind charitable donations like conformity, social norms, and reciprocity.\nThe key hypotheses in this experiment are:\n\nPresence of a Matching Grant Increases Giving: Donors are more likely to contribute when a matching grant is offered, compared to when no match is offered.\nHigher Match Ratios Lead to Higher Giving: Increasing the match ratio (e.g., from $1:$1 to $2:$1 or $3:$1) will further increase donation rates and total contributions by making the “price” of giving lower.\nLarger Matching Grant Pools Increase Giving: Announcing a larger maximum size of the matching fund (e.g., $100,000 vs. $25,000) will lead to greater donations due to perceived urgency, credibility, or impact.\nHigher Suggested Donation Amounts Influence Giving: Presenting donors with higher suggested donation amounts will lead to larger contributions, possibly by anchoring their perception of a “typical” or expected gift.\nDonor Responsiveness to Matching Grants Varies by Political Context: Donors living in different political environments (e.g., red vs. blue states) will respond differently to the match offer, potentially due to identity, perceived relevance, or local norms.\n\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project 2/index.html#data",
    "href": "projects/project 2/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset comprises over 50,000 individual-level observations from a natural field experiment testing how matching grants affect charitable giving. Each observation represents a prior donor to a politically liberal nonprofit organization in the U.S., who received a direct mail solicitation in 2005. The data include detailed treatment indicators, such as whether the individual received a matching grant (treatment), the match ratio (1:1, 2:1, or 3:1), the maximum match pool size (e.g., $25k, $50k), and suggested donation amounts based on their past giving. A tabulated description of the data variables id provided below, followed by a more detailed description:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code"
  },
  {
    "objectID": "projects/project 2/index.html#data-description-stats",
    "href": "projects/project 2/index.html#data-description-stats",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data Description Stats",
    "text": "Data Description Stats\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nask1\nask2\nask3\namount\ngave\namountchange\nhpa\nfreq\nyears\nmrm2\nnonlit\ncases\nstatecnt\nstateresponse\nstateresponset\nstateresponsec\nstateresponsetminc\nperbush\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n50083\n50083\n50083\n50083\n50083\n50083\n50083\n50083\n50083\n50083\n50082\n50082\n49631\n49631\n50083\n50083\n50083\n50080\n50080\n50048\n48217\n48047\n48217\n48221\n48209\n48214\n48215\n48217\n\n\n0.666813\n0.333187\n71.5018\n91.7927\n111.046\n0.915694\n0.0206457\n-52.672\n59.385\n8.03935\n6.09754\n13.0073\n2.47392\n1.49977\n5.99882\n0.0206269\n0.0219885\n0.0177167\n0.00427312\n0.48794\n0.819599\n0.0867098\n0.321694\n2.42901\n54815.7\n0.669418\n0.391661\n0.871968\n\n\n0.471357\n0.471357\n101.729\n127.253\n151.674\n8.70739\n0.142197\n1267.1\n71.1799\n11.3945\n5.50349\n12.0814\n1.96153\n1.15514\n5.74599\n0.0051708\n0.00625721\n0.00751621\n0.00911209\n0.0787327\n0.16856\n0.135868\n0.103039\n0.378105\n22027.3\n0.193405\n0.186599\n0.258633\n\n\n0\n0\n25\n35\n50\n0\n0\n-200412\n0\n0\n0\n0\n0\n0\n0.00199481\n0\n0\n0\n-0.047619\n0.0909091\n0.00941798\n0\n0\n0\n5000\n0\n0\n0\n\n\n0\n0\n35\n45\n55\n0\n0\n-50\n30\n2\n2\n4\n1\n1\n1.83323\n0.0181635\n0.0184932\n0.0128617\n-0.00138826\n0.444444\n0.755845\n0.0147292\n0.258311\n2.21\n39181\n0.560222\n0.235647\n0.884929\n\n\n1\n0\n45\n60\n70\n0\n0\n-30\n45\n4\n5\n8\n3\n1\n3.5388\n0.0197095\n0.0216972\n0.0198814\n0.00177869\n0.484848\n0.872797\n0.0365541\n0.305534\n2.44\n50673\n0.712296\n0.373744\n1\n\n\n1\n1\n65\n85\n100\n0\n0\n-25\n60\n10\n9\n19\n4\n2\n9.60702\n0.0230482\n0.0247027\n0.0208062\n0.0105448\n0.525253\n0.938827\n0.090882\n0.369132\n2.66\n66005\n0.816798\n0.530036\n1\n\n\n1\n1\n1500\n1875\n2250\n400\n1\n275\n1000\n218\n95\n168\n6\n4\n17.3688\n0.0769231\n0.111111\n0.0526316\n0.111111\n0.731959\n1\n0.989622\n0.997544\n5.27\n200001\n1\n1\n1\n\n\n\n\nThe donation rate across the sample was around 2.1%, and the average change in donation amount was a decrease of $52.67, reflecting the typical non-responsiveness of most individuals.\nDonor histories show that the average highest prior contribution was about $59.39, and the typical donor had given eight times over six years, with about 13 months since their last gift. Roughly 49% were small prior donors (last gift under $35), and 51% had been donors for five or more years, suggesting a base of moderately engaged supporters. The donor base was predominantly male—only 28% of donors were female—and about 9% were identified as couples, which could potentially reflect joint giving decisions or household-level donation behavior.\nIn terms of geographic and political context, 40% of donors were from red states, 60% from blue states, and about half lived in red counties. The average vote share for George W. Bush in the donors’ states was just under 49%, with around 18.5% living in politically competitive states (close25). The treatment increased the average response rate by about 0.43 percentage points, with the treated group’s response rate at 2.2%, compared to 1.8% in the control. Additionally, the nonprofit was moderately active in most states, averaging about 2.47 nonlitigation events (public education campaigns, policy advocacy or lobbying, community organizing public events or speaking engagements etc.) and 1.5 legal cases per state, offering a measure of the organization’s local visibility.\nFinally, the dataset includes zip-code-level demographics that add further context to donor behavior. On average, zip codes were 82% white, with about 32% of the population aged 18–39. The median household income was approximately $54,816, and about 67% of residents were homeowners. Nearly 39% had at least a bachelor’s degree and 87% lived in urban areas. Majority of the donors were male (72.2%). These contextual data allow for analysis of how local socioeconomic factors interact with donor responses to the match offer, enriching the study’s implications for both behavioral economics and nonprofit strategy.\n\nDistribution and Frequency Plots of Donation Amount from donors who gave based on past donation and financial status data and variables being modified\n\nThe distributions of key variables reveal that most donors in the experiment were low-frequency, small-dollar contributors, with past donations typically under $100 and fewer than 10 total gifts. While a few donors were highly engaged or generous, they were the exception. The years since first donation were spread relatively evenly, suggesting a mix of both new and long-term supporters. Most recent donations occurred within the last few months, indicating a strong recency effect. Donors primarily lived in zip codes with median household incomes between $30,000 and $70,000, though some resided in wealthier areas.\nOn the experimental side, the match ratio, match threshold, and suggested donation amount were all well balanced across groups, with no major disparities—indicating successful randomization. These distributions support the validity of comparisons across treatment groups and suggest that variables like recency of donation and donor longevity may be strong predictors of giving behavior.\n\n\nDistribution and Frequency Plots of Donation Amount from donors who gave based on donor characteristics, geopolitical context, and location (zipcode) demographics\n\nThe visualizations show how donation amounts vary across donor characteristics, political context, and zip-code demographics. Donors who were previously small contributors (ltmedmra = 1) or had donated for over 5 years (year5 = 1) gave slightly more on average. Male donors gave more than female donors, and donors from blue states (red0 = 0) gave higher amounts than those from red states. Donation amounts increased with moderate values of Bush vote share (perbush) but not at extremes. Donations also varied non-linearly with the number of non-litigation activities in a state (nonlit). From a demographic perspective, donation amounts peaked among donors from zip codes with moderate income levels, higher homeownership (powner), and moderately educated areas (psch_atlstba), suggesting that both neighborhood affluence and stability may influence giving behavior.\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another."
  },
  {
    "objectID": "projects/project 2/index.html#experimental-results",
    "href": "projects/project 2/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nThe proportion of donors who made a donation in the treatment group was 2.2%, compared to 1.8% in the control group, wchih seems roughly equivalent. However, this also suggests that the matching grant increased the likelihood of making a donation by about 0.4 percentage points, or roughly 22% relative to the control group. It is also to be noted that participants were randomly assigned to either a control group (approximately one-third of the sample) or a treatment group (the remaining two-thirds), suggesting that the treatment group may have more statistical power to detect differences in the response rate.\n\nImpact of Matching Gifts on Donation Likelihood: Evidence from a Bivariate Regression\nNext in my analysis, I ran a bivariate linear regression to test whether being in the treatment group—receiving a letter that included a matching donation offer—increased the likelihood of making a charitable donation. Using the binary outcome variable gave, I found that being in the treatment group increased the probability of donating by approximately 0.42 percentage points (coefficient 0.0042), keeping all else constant, while the intercept (0.0179) tells us the predicted probability of donating for someone in the control group. This result was statistically significant (p = 0.0019), indicating a real and measurable effect that is unlikely due to chance. The results are documented here:\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStandard Error\nt-Statistic\np-Value\nCI Lower (95%)\nCI Upper (95%)\n\n\n\n\nconst\n0.0178582\n0.00110068\n16.2246\n4.77903e-59\n0.0157009\n0.0200156\n\n\ntreatment\n0.00418035\n0.00134791\n3.10136\n0.0019274\n0.00153844\n0.00682227\n\n\n\nMy findings closely match the descriptive statistics reported in Table 2A, Panel A of the paper, which shows a response rate of 2.2% for the treatment group versus 1.8% for the control group—also a 0.4 percentage point difference. While small in absolute terms, this represents a 22% relative increase in giving behavior, suggesting that individuals are more likely to donate when they believe their contribution will have greater impact. This supports the broader conclusion of the study: that subtle nudges, like matching gifts, can meaningfully influence human behavior by increasing the perceived value of giving. The result reinforces the idea that charitable behavior is not just about fixed generosity levels, it’s also about how the opportunity to give is presented.\n\n\nTreatment or Control Group Assignment Effect on Donor Behavior: Probit Evidence from a Charitable Giving Experiment\nFollowing this, I ran a Probit regression to examine whether being assigned to the treatment group (receiving a fundraising letter that included a matching donation offer) or control group affected the likelihood of making a charitable donation. The model found a positive and statistically significant treatment effect, with a coefficient of 0.0868 and a p-value of 0.0019, indicating the result is statistically significant, and unlikely due to chance.While the coefficient itself isn’t directly interpretable in percentage points (as it is in linear regression), the positive sign means that individuals in the treatment group were more likely to donate than those in the control group. The results are as follows:\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStandard Error\nt-Statistic\np-Value\nCI Lower (95%)\nCI Upper (95%)\n\n\n\n\nconst\n0.0178582\n0.00110068\n16.2246\n4.77903e-59\n0.0157009\n0.0200156\n\n\ntreatment\n0.00418035\n0.00134791\n3.10136\n0.0019274\n0.00153844\n0.00682227\n\n\n\nThis aligns with earlier findings from the linear regression and confirms the descriptive results shown in Table 2A, where donation rates were higher in the treatment group.\nTherefore, this result reinforces that people who received a letter offering a matching donation were more likely to give than those who did not. While the actual increase in probability isn’t directly visible from the Probit coefficient, the positive and significant effect confirms that the matching offer changed behavior. This suggests that people are responsive to how giving is framed, in this case, making their contribution feel more impactful through a match. Even when the baseline donation rate is low, a small psychological nudge like a match can increase engagement and drive meaningful behavior change.\nNOTE: Linear regression results appear replicate Table 3 column 1 in the paper. Probit results do not, despite Table 3 indicating its results come from probit regressions.Probit regression results don’t match Table likely, because that table reports marginal effects (the estimated change in probability of donating when moving from control to treatment) than the raw coefficients from a Probit model. However, my Probit regression includes only the basic treatment indicator and outputs the raw coefficient, not the marginal effect. In a linear probability model (ordinary least squares on a binary outcome), the coefficient directly estimates the marginal effect, which is why the linear regression results match table 3 column 1.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nUsing a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not\n\n\n\n\n\n\n\n\n\n\n\n\nComparison\nGroup 1 Mean Donation Rate\nGroup 2 Mean Donation Rate\nMean Diff (pp)\nT-Statistic\nCritical Value (±)\nConclusion\n\n\n\n\n2:1 vs 1:1\n2.26\n2.07\n0.19\n0.965\n1.9601\nNot Significant\n\n\n3:1 vs 1:1\n2.27\n2.07\n0.2\n1.015\n1.9601\nNot Significant\n\n\n3:1 vs 2:1\n2.27\n2.26\n0.01\n0.0501\n1.9601\nNot Significant\n\n\n\nTo test whether the size of the match ratio affected donation behavior, I conducted a series of t-tests comparing donation rates across 1:1, 2:1, and 3:1 match groups. The results show that while donation rates were slightly higher for the 2:1 (2.26%) and 3:1 (2.27%) match groups compared to the 1:1 group (2.07%), these differences were not statistically significant at the 95% confidence level. Similarly, there was no meaningful difference between the 3:1 and 2:1 groups. All t-statistics were well below the critical threshold of 1.96, and all p-values exceeded 0.05.\nThese findings suggest that simply increasing the generosity of the match offer, from 1:1 to 2:1 or 3:1, did not significantly increase the likelihood that someone would donate. In other words, while matching gifts appear to influence behavior overall, there is no strong evidence that larger match ratios (beyond 1:1) further increase donation rates. This directly aligns with authors’ statement in page 8 that larger match ratios (2:1, 3:1) did not have a meaningful influence on donation behavior, at least not in a statistically significant way. This confirms the idea that donors respond to the presence of a match offer, but are not particularly sensitive to how generous the match is.\n\n\nUsing a series of linear regressions to test whether the size of the match ratio has an effect on whether people donate or not\nI ran a linear regression to evaluate whether the size of the match ratio (1:1, 2:1, or 3:1) had an effect on the likelihood of making a donation (gave, a binary variable). The model included dummy variables ratio1, ratio2, and ratio3 as independent variables, representing each of the three match groups. “ratio1” was created by flagging the cases where raio2 and ratio3 are 0, in the treatment group. The regression included a constant term, so the effect of each ratio variable is measured relative to an implicit baseline (control group).\nIt is observed from the results of the linear regression that All three coefficients (ratio1, ratio2, and ratio3) are extremely large negative numbers (~-1.23e+10), and all are identical, which is a red flag. The standard errors are also enormous (~1.54e+11), resulting in very small t-statistics (≈ -0.08) and very high p-values (~0.936). Moreover, none of the coefficients are statistically significant, and the model R² is effectively 0, meaning the model explains none of the variation in donation behavior.\nThe results show clear signs of a severe multicollinearity or design matrix error, likely caused by including all three dummy variables (ratio1, ratio2, ratio3) without dropping a reference group. Since the three dummies are mutually exclusive and exhaustive (they sum to 1), including all of them with a constant creates a perfect linear dependency, which leads to a singular matrix and unreliable coefficient estimates. To fix this, I omit one of the ratio dummies (e.g., drop ratio1) so that the remaining coefficients (ratio2 and ratio3) are interpreted relative to the 1:1 match group.\nThe results now show the following:\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStandard Error\nt-Statistic\np-Value\nCI Lower (95%)\nCI Upper (95%)\n\n\n\n\nconst\n0.0190151\n0.000852479\n22.3056\n1.11719e-109\n0.0173442\n0.020686\n\n\nratio2\n0.00361828\n0.00159454\n2.26917\n0.023262\n0.000492971\n0.00674359\n\n\nratio3\n0.0037183\n0.00159479\n2.33153\n0.0197294\n0.000592493\n0.00684411\n\n\n\n\nThe intercept (0.0190) indicates that the average donation rate in the 1:1 match group was approximately 1.9%.\n\nThe coefficient for ratio2 is 0.0036, which means that the 2:1 match group donated at a rate that was 0.36 percentage points higher than the 1:1 group. This effect is statistically significant at the 5% level (p = 0.023).\n\nThe coefficient for ratio3 is 0.0037, meaning the 3:1 match group donated 0.37 percentage points more than the 1:1 group. This is also statistically significant (p = 0.020).\n\nIt is also to be noted that the model R^ is effectively 0, indicating that the model explains almost none of the variation in donation behavior.\n\n\nThus, the regression provides evidence that larger match ratios do modestly increase the likelihood of donating, compared to a standard 1:1 match. While the increases (less than half a percentage point) are small in absolute terms, they are statistically significant, suggesting that donors do respond to more generous match offers, even if the effect size is limited. This complements earlier t-test findings and supports the idea that match generosity does matter, but only slightly.\n\n\nResponse rate difference between 1:1, 2:1, and 3:1 match ratios\nI now calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios, both directly from the data and from the differences in the fitted coefficients in the previous regression. The response rates are as follows:\n2:1 vs 1:1 response rate difference: 0.0019 3:1 vs 2:1 response rate difference: 0.0001 Response rate difference from coefficients (2:1 - 1:1): 0.0036 Response rate difference from coefficients (3:1 - 2:1): 0.0001\nThese results suggest that increasing the match ratio from 1:1 to 2:1 has a modest but meaningful effect on donor behavior (The 2:1 match group donated at a rate 0.19 percentage points higher as per the data, and 0.36 percentage points higher as per the difference from the coefficients, than the 1:1 group). However, increasing the match further from 2:1 to 3:1 offers almost no additional benefit (0.0001). Donors seem responsive to the presence and basic enhancement of a match, but not to increasingly generous match sizes beyond a certain point.\nNOTE: The small difference between your raw mean comparison and regression coefficient comes from how OLS regression estimates parameters (by minimizing squared errors)\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nT-test of donation amount on the treatment status\nFirst, I conduct a t-test to compare the average donation amount between individuals in the treatment group (who received a matching gift offer) and those in the control group (no match).\nThe analysis included all individuals, regardless of whether they donated or not. The Mean donation (treatment group) is $0.97 and the Mean donation (control group) is $0.81. The observed t-stat was 1.9182, at a p-value of 0.0551, which is statistically insignificant.While the treatment group gave slightly more on average, the p-value is just above the conventional 0.05 threshold, meaning the result is not statistically significant at the 95% confidence level.\nOverall, this analysis suggests that people who received a matching gift offer tended to donate more on average, but the evidence is not strong enough to confirm that this difference is due to the treatment rather than random chance. The p-value (0.055) is close to the significance cutoff, which means there might be a weak effect, but it’s not statistically conclusive.\n\n\nT-test of donation amount on the treatment status using only data from people who actually donated\nI also conducted an analysis including only individual from both group who donated (gave == 1). The mean donation among the treatment group was $43.87, while the control group gave slightly more on average, at $45.54. The observed t-statistic was -0.581 with a p-value of 0.561, which is well above the conventional 0.05 threshold. Similar to the analysis above, this means the difference is not statistically significant at the 95% confidence level, and we cannot conclude that the treatment had an effect on donation amount among donors.\nConfirming the t-stat and p-values using a bivariate regression of amount on treatment, conditional on donation, I took a deeper look at the regression coefficients. The regression coefficient for treatment is -1.67, meaning that, on average, donors in the treatment group gave $1.67 less than those in the control group, keeping all else constant. However, this difference is not statistically significant (p = 0.561), and the confidence interval ranges from about –$7.31 to +$3.97, meaning the true effect could easily be zero or even slightly positive. The results are as follows:\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStandard Error\nt-Statistic\np-Value\nCI Lower (95%)\nCI Upper (95%)\n\n\n\n\nconst\n45.5403\n2.42338\n18.7921\n5.47358e-68\n40.785\n50.2956\n\n\ntreatment\n-1.66839\n2.87238\n-0.580839\n0.561476\n-7.30477\n3.96799\n\n\n\nOverall, the analysis results do not support the idea that matching gifts increase donation size once someone is already giving. It is also to be noted that, by restricting the analysis to only people who gave, there is potential conditioning on a post-treatment outcome, and that can introduce selection bias. Therefore, the coefficient no longer reflects a clean causal effect, it’s just a descriptive comparison among people who chose to give. However, in the full sample, since treatment group was randomly assigned, there’s no systematic difference between the treatment and control groups, also verified by the mostly balanced dataset in the analysis in the first section, so the treatment effect can be interpreted as a causal effect.\n\n\nHistogram plots of donation amounts for treatment and control groups, only among people who donated\n\nThe histograms display the distribution of donation amounts among individuals who donated, separated by treatment and control groups. Both groups exhibit a strong right skew, with most donations falling below $100 and a small number of large donations extending the tail of the distribution. The treatment group shows a higher concentration of smaller donations, while the control group has a slightly more even spread, including more mid-sized donations. The mean donation amount is slightly higher in the control group ($45.54) compared to the treatment group ($43.87), but this difference is small and not statistically significant, as seen in the analysis above."
  },
  {
    "objectID": "projects/project 2/index.html#simulation-experiment",
    "href": "projects/project 2/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made (control).\n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made (treatment).\n\n\n\nLaw of Large Numbers\nSimulating 10,000 draws from the control distribution and 10,000 draws from the treatment distribution, using a Bernoulli distribution. I then calculate a vector of 10,000 pairwise differences between each treatment and control outcome, and then plot the cumulative average of that vector of differences.\n\nAt the beginning (small sample sizes), the average is highly variable and “noisy”, sometimes jumping well above or below the true value (0.004).\nAs more simulations are added, the cumulative average should settle down and converges toward the true treatment effect of 0.004, shown by the red dashed line. However, in my plot, the cumulative average converges slightly above the true treatment effect. This is likely due to the random nature of the simulation, as a result of which our sample has slightly more donors than expected in the treatment group/ slightly fewer donors than expected in the control group. Or it could be that in this first run, the simulated sample overestimated the effect of treatment slightly and converged at around 0.007.\n\nUpon running the simulation a second time, and other subsequent runs, a plot similar to the one above is observed, where, as per the Law of Large Numbers the sample average eventually converges to the true average in expectation, at 0.004. This chart shows that even though individual samples may vary due to chance, the average across many independent observations eventually reflects the true underlying effect. This is the statistical foundation behind large-scale experiments and why we rely on big samples for inference.\nThe following Python code simulates 10,000 Bernoulli trials from a control and treatment group, calculates their cumulative average difference, and plots the result.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# True probabilities\np_control = 0.018  # do not get any charitable match\np_treatment = 0.022  # get a charitable match of any size\n\nn = 10000\n\n# Simulate 10,000 Bernoulli draws from each group\ncontrol = np.random.binomial(1, p_control, n)\ntreatment = np.random.binomial(1, p_treatment, n)\n\n# Compute differences between each draw (pairwise)\ndifferences = treatment - control  # each element is 0, +1, or -1\n\n# Cumulative average of the differences\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n + 1)\n\n# Plotting\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff, label=\"Cumulative Average of Differences\", color='blue')\nplt.axhline(0.004, color='red', linestyle='--', label=\"True Treatment Effect (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.title(\"Simulation Demonstrating Law of Large Numbers\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nIn order to explore the Central Limit Theorem, I generated four histograms of the average differences between treatment and control groups at sample sizes of 50, 200, 500, and 1000. Each histogram represents the distribution of the average differences in treatment and control groups (using two Bernoulli distributions: control group with a 1.8% donation rate, treatment group with a 2.2% donation rate) from 1000 simulations at each sample size.\n\nThis sequence of histograms demonstrates the Central Limit Theorem by showing how the distribution of average treatment effects becomes more normal and concentrated as the sample size increases. Each histogram represents 1,000 simulated differences in donation rates between treatment and control groups, using sample sizes of 50, 200, 500, and 1,000. At smaller sample sizes, the distribution of average effects is wide and irregular, reflecting high variability. As the sample size grows, the distributions become more bell-shaped, centered near the true treatment effect of 0.004, and show reduced spread. This illustrates that as sample size increases, the sampling distribution of the average treatment effect becomes approximately normal and more precise—just as the Central Limit Theorem predicts.\nThe following Python code Simulates 1,000 experiments for each of 4 different sample sizes (n = 50, 200, 500, 1000), collects the 1,000 differences and plots a histogram for each sample size.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\n# Create subplots\nfig, axs = plt.subplots(1, 4, figsize=(20, 5), sharey=True)\n\nfor i, n in enumerate(sample_sizes):\n    mean_diffs = []\n    \n    for _ in range(num_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        mean_diffs.append(diff)\n    \n    # Plot histogram\n    axs[i].hist(mean_diffs, bins=30, color='skyblue', edgecolor='black')\n    axs[i].axvline(0.004, color='red', linestyle='--', label='True Treatment Effect')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Avg. Treatment Effect\")\n    axs[i].legend()\n\naxs[0].set_ylabel(\"Frequency\")\nplt.suptitle(\"Demonstrating the Central Limit Theorem\", fontsize=16)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\n\n\nDetailed Code Jupternotebook\nYou can download and view the full Jupyter notebook that contains the analysis:\n\n\n\n⬇️ Download Notebook"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\nKowsalya Nitya Vootla\nApr 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Late Delivery Risk for a Sport Retail Business\n\n\n\n\nNitya Kowsalya Vootla\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]